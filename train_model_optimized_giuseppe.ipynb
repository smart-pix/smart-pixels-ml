{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec3747-31c9-451d-b06b-fe4e589ed725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e30cc2-2e02-447e-a79e-189d71bf188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove TF warnings (this can be dangerous)\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23456d02-c5e1-4f81-b8f3-c8c5367dc0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://gist.github.com/zrruziev/b93e1292bf2ee39284f834ec7397ee9f\n",
    "# sudo echo 0 | sudo tee -a /sys/bus/pci/devices/0000\\:01\\:00.0/numa_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24773cdc-4bbe-48c3-9910-8b39c38bfc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 16:02:23.261089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-02 16:02:24.231727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from qkeras import *\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import json\n",
    "import random\n",
    "import psutil\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da258a7-b1d2-4afe-aa30-2ddb31150ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can disable the GPU, if a GPU is present\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac065e8-fcf2-44a0-8dee-e1e44e605137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.OptimizedDataGenerator import OptimizedDataGenerator\n",
    "from loss import *\n",
    "from models.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a4fab-9a72-4728-ac5d-09fbd6f6afd8",
   "metadata": {},
   "source": [
    "#### Scaling Lists for Different Pixel Pitches (dataset_2s):\n",
    "* 100x25x100 um:  [150.0, 37.5, 10.0, 1.22]\n",
    "* 50x25x100 um:   [75.0, 37.5, 10.0, 1.22]\n",
    "* 50x20x100 um:   [75.0, 30.0, 10.0, 1.22]\n",
    "* 50x15x100 um:   [75.0, 22.5, 10.0, 1.22]\n",
    "* 50x12.5x100 um: [75.0, 18.75, 10.0, 1.22]\n",
    "* 50x10x100 um:   [75.0, 15.0, 10.0, 1.22]\n",
    "\n",
    "#### Scaling Lists for Different Pixel Pitches (dataset_3sr):\n",
    "* 100x25x100 um:  [150.0, 37.5, 10.0, 10.0]\n",
    "* 50x25x100 um:   [75.0, 37.5, 10.0, 10.0]\n",
    "* 50x20x100 um:   [75.0, 30.0, 10.0, 10.0]\n",
    "* 50x15x100 um:   [75.0, 22.5, 10.0, 10.0]\n",
    "* 50x12.5x100 um: [75.0, 18.75, 10.0, 10.0]\n",
    "* 50x10x100 um:   [75.0, 15.0, 10.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1a0184-55a3-4294-b0df-b3067d9bb72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n",
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "val_batch_size = 5000\n",
    "train_file_size = 50\n",
    "val_file_size = 10\n",
    "\n",
    "# See: https://docs.google.com/document/d/1ZoqVyJOOAXhzt2egMWh3OoNJ6lWq5lNR6sjcYON4Vlo/edit?tab=t.0#heading=h.k6tyal7z5t5l\n",
    "dataset_name = \"dataset_2s\"\n",
    "# 50x12.5x100 micron pixel sensor => 13x21 pixel sensor array\n",
    "sensor_geometry_name = \"50x12P5x100\"\n",
    "# Either 20 or 2 timeslices\n",
    "timeslices_name = \"timeslices20\" if timeslices_all_enable else \"timeslices2\"\n",
    "timeslices_range = -1 if timeslices_all_enable else [0, 19]\n",
    "timeslices_val = 20 if timeslices_all_enable else 2\n",
    "#\n",
    "batch_size_name = f\"bs{batch_size}\"\n",
    "\n",
    "# Input: parquets\n",
    "data_dir = f\"{data_base_dir}/dataset_2s_50x12P5_parquets/unflipped/recon3D/\"\n",
    "labels_dir = f\"{data_base_dir}/dataset_2s_50x12P5_parquets/unflipped/labels/\"\n",
    "\n",
    "# Output: tfrecords\n",
    "tfrecords_dir_train = f\"{tfrecords_base_dir}/tfrecords_{dataset_name}_{sensor_geometry_name}_{timeslices_name}_{batch_size_name}_train\"\n",
    "tfrecords_dir_val = f\"{tfrecords_base_dir}/tfrecords_{dataset_name}_{sensor_geometry_name}_{timeslices_name}_{batch_size_name}_val\"\n",
    "\n",
    "training_generator = OptimizedDataGenerator(\n",
    "    data_directory_path = \"/data/dajiang/smartPixels/dataset_3s/dataset_3sr_100x25x150_parquets/unflipped/recon3D/\",\n",
    "    labels_directory_path = \"/data/dajiang/smartPixels/dataset_3s/dataset_3sr_100x25x150_parquets/unflipped/labels/\",\n",
    "    is_directory_recursive = False,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = batch_size,\n",
    "    file_count = train_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    scaling_list = [75.0, 18.75, 10.0, 1.22],\n",
    "    input_shape = (timeslices_val,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    files_from_end = True,\n",
    "    shuffle = True,\n",
    "\n",
    "    load_from_tfrecords_dir = \"/data/dajiang/smartPixels/tfrecords/tfrecords_dataset_3sr_100x25x150_20t_bs5000_train\",\n",
    "    tfrecords_dir = tfrecords_dir_train,\n",
    "    use_time_stamps = timeslices_range,\n",
    "    max_workers = 1, # Don't make this too large (will use up all RAM)\n",
    "    seed = 10,\n",
    "    quantize = True # Quantization ON\n",
    ")\n",
    "\n",
    "validation_generator = OptimizedDataGenerator(\n",
    "    data_directory_path = \"/data/dajiang/smartPixels/dataset_3s/dataset_3sr_100x25x150_parquets/unflipped/recon3D/\",\n",
    "    labels_directory_path = \"/data/dajiang/smartPixels/dataset_3s/dataset_3sr_100x25x150_parquets/unflipped/labels/\",\n",
    "    is_directory_recursive = False,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = val_batch_size,\n",
    "    file_count = val_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    scaling_list = [75.0, 18.75, 10.0, 1.22],\n",
    "    input_shape = (timeslices_val,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    files_from_end = True,\n",
    "    shuffle = True,\n",
    "\n",
    "    load_from_tfrecords_dir = \"/data/dajiang/smartPixels/tfrecords/tfrecords_dataset_3sr_100x25x150_20t_bs5000_val\",\n",
    "    tfrecords_dir = tfrecords_dir_val,\n",
    "    use_time_stamps = timeslices_range,\n",
    "    max_workers = 1, # Don't make this too large (will use up all RAM)\n",
    "    seed = 10,\n",
    "    quantize = True # Quantization ON\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd324b5a-9a82-4b57-9de0-94ba5e76715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 16:03:10.736112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3234 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 1g.5gb, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch = 0\n",
      "(5000, 13, 21, 20)\n",
      "(5000, 4)\n",
      "batch = 1\n",
      "(5000, 13, 21, 20)\n",
      "(5000, 4)\n",
      "batch = 2\n",
      "(5000, 13, 21, 20)\n",
      "(5000, 4)\n",
      "batch = 3\n",
      "(5000, 13, 21, 20)\n",
      "(5000, 4)\n",
      "batch = 4\n",
      "(5000, 13, 21, 20)\n",
      "(5000, 4)\n",
      "batch = 5\n",
      "(5000, 13, 21, 20)\n",
      "(5000, 4)\n"
     ]
    }
   ],
   "source": [
    "num_batches = validation_generator.__len__()\n",
    "print(num_batches)\n",
    "\n",
    "X_val_all = []\n",
    "y_val_all = []\n",
    "\n",
    "num_batches = validation_generator.__len__() # The total number of batches for the validation dataset\n",
    "#val_num_batches = 1\n",
    "\n",
    "for i_batch in range(num_batches): # Loop over all batches\n",
    "    X_val, y_val = validation_generator.__getitem__(i_batch)\n",
    "    X_val = X_val.numpy()\n",
    "    y_val = y_val.numpy()\n",
    "    X_val_all.append(X_val)\n",
    "    y_val_all.append(y_val)\n",
    "\n",
    "X_val_all = np.array(np.concatenate(X_val_all))\n",
    "y_val_all = np.array(np.concatenate(y_val_all))\n",
    "\n",
    "os.makedirs(npy_base_dir, exist_ok=True)\n",
    "np.save(f\"{npy_base_dir}/X_{timeslices_name}_val.npy\", X_val_all)\n",
    "np.save(f\"{npy_base_dir}/y_{timeslices_name}_val.npy\", y_val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fd3960-c7f1-4d6c-b7e0-0c4c833797d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 21, 20)]      0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepar  (None, 11, 19, 5)         285       \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 11, 19, 5)         0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 11, 19, 5)         30        \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 11, 19, 5)         0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 3, 6, 5)           0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 3, 6, 5)           0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1456      \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 16)                272       \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2281 (8.91 KB)\n",
      "Trainable params: 2281 (8.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compiles model\n",
    "model = CreateModel((13,21,timeslices_val), n_filters=5, pool_size=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870b8741-98fd-4e1e-bc29-7b9fcbb9b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d3ecb0d-5db2-4610-bd58-e55d06f049a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 02:16:31.017164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n",
      "2024-11-15 02:16:31.249887: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-15 02:16:31.689255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-11-15 02:16:31.710408: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x7fa2a4bdbae0\n",
      "2024-11-15 02:16:31.786865: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f847cb3f780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-15 02:16:31.786916: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB MIG 1g.5gb, Compute Capability 8.0\n",
      "2024-11-15 02:16:31.816761: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-15 02:16:31.921051: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-15 02:16:31.987969: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "pitch = '100x25x150'\n",
    "date = '14Nov2024'\n",
    "base_dir = '/home/dajiang/smart-pixels-ml/weights/weights_7pitches/weights-{}-bs{}-{}-checkpoints'.format(pitch, batch_size, date)\n",
    " \n",
    "os.mkdir(base_dir)\n",
    "checkpoint_filepath = base_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    ")\n",
    "\n",
    "best_model_hdf5 = f\"{model_base_dir}/weights_7pitches/best_model_{model_name}.hdf5\"\n",
    "best_model_keras = f\"{model_base_dir}/weights_7pitches/best_model_{model_name}.keras\"\n",
    "best_model_weights_hdf5 = f\"{model_base_dir}/weights_7pitches/best_model_{model_name}_weights.hdf5\"\n",
    "best_model_weights_keras = f\"{model_base_dir}/weights_7pitches/best_model_{model_name}_weights.keras\"\n",
    "best_model_architecture_json = f\"{model_base_dir}/weights_7pitches/best_model_{model_name}_architecture.json\"\n",
    "\n",
    "if not load_model_from_hdf5_enabled:\n",
    "    # training\n",
    "    es = EarlyStopping(\n",
    "        patience=50,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    checkpoint_base_dir = f\"{model_base_dir}/weights_7pitches/{dataset_name}_{sensor_geometry_name}_{timeslices_name}_{batch_size_name}\"  + (\"_bnorm\" if batch_norm_enabled else \"\") + \"-checkpoints\"\n",
    "\n",
    "    os.makedirs(checkpoint_base_dir, exist_ok=True)\n",
    "    checkpoint_filepath = checkpoint_base_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'\n",
    "    mcp = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=False,\n",
    "    )\n",
    "\n",
    "    class ScalePrintingCallback(keras.callbacks.Callback):    \n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            scale_layer = self.model.layers[-1]\n",
    "            print(\n",
    "                f\"scaling layer ({epoch}):\", \n",
    "                scale_layer.scale, \n",
    "                tf.math.softplus(scale_layer.scale)\n",
    "            )\n",
    "\n",
    "    print_scale = ScalePrintingCallback()\n",
    "    \n",
    "    history = model.fit(x=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        callbacks=[mcp],\n",
    "                        epochs=100,\n",
    "                        shuffle=False, # shuffling now occurs within the data-loader\n",
    "                        verbose=1)\n",
    "\n",
    "    # Revert to best model\n",
    "    files = os.listdir(checkpoint_base_dir)\n",
    "    vlosses = [float(f.split(\"-v\")[1].split(\".hdf5\")[0]) for f in files]\n",
    "    bestfile = files[np.argmin(vlosses)]\n",
    "    model.load_weights(f\"{checkpoint_base_dir}/{bestfile}\")\n",
    "\n",
    "    # Save (best) model information to file\n",
    "    model.save(best_model_hdf5)\n",
    "    model.save(best_model_keras)\n",
    "    model.save_weights(best_model_weights_hdf5)\n",
    "    model.save_weights(best_model_weights_keras)\n",
    "    model_json = model.to_json()\n",
    "    with open(best_model_architecture_json, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "else:\n",
    "    co = {\"custom_loss\": custom_loss}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    # This overrides the previously compiled model\n",
    "    # TODO: load just weights\n",
    "    model = load_model(best_model_hdf5, custom_objects=co)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd172d9c-ac6d-497a-8391-dc507cb3cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_validation_loss_png = f\"{model_base_dir}/weights_7pitches/training_validation_loss_{model_name}.png\"\n",
    "if load_model_from_hdf5_enabled:\n",
    "    from PIL import Image\n",
    "    img = Image.open(training_validation_loss_png)\n",
    "    img.show()  # Opens the image in the default viewer\n",
    "else: \n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(training_validation_loss_png)  # Save as PNG\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e97ac-8928-4833-86a3-dabef8c21bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
